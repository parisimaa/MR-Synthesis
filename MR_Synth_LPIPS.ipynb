{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Egj20bQVLIg",
        "outputId": "8743ef40-d4e0-4c09-b571-1794017cf7b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lpips in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.0->lpips) (12.4.127)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install lpips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crBXUTyOdVWX",
        "outputId": "b047ab5b-a96a-409d-820f-be3bcc2f277d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyy01SJcdm3p",
        "outputId": "3a525cc9-d4f1-4bca-ed57-f0996fdea207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: elasticdeform in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from elasticdeform) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from elasticdeform) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install elasticdeform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIk23AGRKogI",
        "outputId": "c0ed654f-acfa-41df-d1fc-8f49029497be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx8Up2bWWJzK"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "import scipy.io as sio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmBs-vH2c2Wt",
        "outputId": "2ceacb95-f97f-49e3-e538-c6645f83049d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "sys.path.append('/content/drive/Othercomputers/My Mac/Documents/GitHub/CCL-Synthetis/trained/CCL-Synthetis/')\n",
        "\n",
        "# Assuming utils and Datagen are your local modules or packages\n",
        "from utils.model_utils import modelObj\n",
        "from Synthesis.synthesis_losses import lossObj\n",
        "from Datagen.h5_pretrain_Synth_Data_Generator import DataLoaderObj\n",
        "\n",
        "import Synthesis.synth_config as cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV5OwsB3dvz5"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "# model_ = modelObj(cfg)\n",
        "#--------------------------------------------\n",
        "# weights = {\n",
        "#     'Baseline': '/content/drive/Othercomputers/My Mac/Documents/GitHub/CCL-Synthetis/trained/weights/ReLU/Loss/brats_t1_t2_flair_loss5/rand_deform/finetune_Hybride _baseline/t1_t2_flair_loss5_tr1_Hybride/tr_comb_Exp1_LR_ft_0.01/weights_20Final.hdf5',\n",
        "#     'Full_Decoder': '/content/drive/Othercomputers/My Mac/Documents/GitHub/CCL-Synthetis/trained/weights/ReLU/Loss/brats_t1_t2_flair_loss5/rand_deform/finetune_Hybride _CL_full_dec_warm/t1_t2_flair_loss5_tr1_Hybride/tr_comb_Exp1_LR_ft_0.01/weights_20Final.hdf5',\n",
        "#     'Partial_Decoder': '/content/drive/Othercomputers/My Mac/Documents/GitHub/CCL-Synthetis/trained/weights/ReLU/Loss/brats_t1_t2_flair_loss5/rand_deform/finetune_Hybride _CL_partial_dec_warm/t1_t2_flair_loss5_tr1_Hybride/tr_comb_Exp1_LR_ft_0.01/weights_20Final.hdf5'\n",
        "# }\n",
        "\n",
        "# model_base = model_.synth_unet(act_name='relu')\n",
        "# model_full = model_.synth_unet(act_name='relu')\n",
        "# model_part = model_.synth_unet(act_name='relu')\n",
        "\n",
        "# # Load weights into models\n",
        "# model_base.load_weights(weights['Baseline'])\n",
        "# model_full.load_weights(weights['Full_Decoder'])\n",
        "# model_part.load_weights(weights['Partial_Decoder'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0-cdSKXW6Wx"
      },
      "outputs": [],
      "source": [
        "sys.path.append('/gpfs/scratch/pa2297/multi-contrast-contrastive-learning/')\n",
        "\n",
        "from utils.utils import myCrop3D\n",
        "from utils.utils import contrastStretch\n",
        "\n",
        "def normalize_img_zmean(img, mask):\n",
        "    ''' Zero mean unit standard deviation normalization based on a mask'''\n",
        "    mask_signal = img[mask>0]\n",
        "    mean_ = mask_signal.mean()\n",
        "    std_ = mask_signal.std()\n",
        "    img = (img - mean_ )/ std_\n",
        "    return img, mean_, std_\n",
        "\n",
        "def normalize_img(img):\n",
        "    img = (img - img.min())/(img.max()-img.min())\n",
        "    return img\n",
        "\n",
        "def load_subject(datadir, subName):\n",
        "    data_suffix = ['_t1ce.nii.gz', '_t2.nii.gz', '_t1.nii.gz', '_flair.nii.gz']\n",
        "    sub_img = []\n",
        "    mask = None\n",
        "    subject_dir = os.path.join(datadir, subName)  # Correctly form the path to the subject's directory\n",
        "\n",
        "    for suffix in data_suffix:\n",
        "        img_path = os.path.join(subject_dir, subName + suffix)  # Correct path to the image file\n",
        "        img_data = nib.load(img_path).get_fdata()\n",
        "        img_data = np.rot90(img_data, -1)\n",
        "        img_data = myCrop3D(img_data, (192,192))\n",
        "\n",
        "        if mask is None:\n",
        "            mask = np.zeros(img_data.shape)\n",
        "            mask[img_data > 0] = 1\n",
        "\n",
        "        img_data = contrastStretch(img_data, mask, 0.01, 99.9)\n",
        "        img_data, mean_, std_ = normalize_img_zmean(img_data, mask)\n",
        "        sub_img.append(img_data)\n",
        "\n",
        "    sub_img = np.stack(sub_img, axis=-1)\n",
        "    sub_img = np.transpose(sub_img, (2, 0, 1, 3))  # Adjust dimensions as needed\n",
        "    sub_img = sub_img[50:120]  # Assuming your volume z-axis slice range\n",
        "\n",
        "    return sub_img\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "\n",
        "def get_data(img, contrast_idx, target_contrast_idx):\n",
        "    \"\"\"Returns tuple (input, target) correspond to sample #idx.\"\"\"\n",
        "    x_train = generate_X(img, contrast_idx)\n",
        "    y_train = generate_Y(img, target_contrast_idx)\n",
        "    return tf.identity(x_train), tf.identity(y_train)\n",
        "\n",
        "def generate_X(img, contrast_idx):\n",
        "    X = img[..., contrast_idx]\n",
        "    return X\n",
        "\n",
        "def generate_Y(img, target_contrast_idx):\n",
        "    Y = img[..., target_contrast_idx]\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDTubnsDXwAC"
      },
      "outputs": [],
      "source": [
        "import lpips\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIQmm4ZjX0Ud",
        "outputId": "bcb5058a-300c-46c8-aab2-12d64f6cdbfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        }
      ],
      "source": [
        "# loss_fn = lpips.LPIPS(net='alex')  # Using AlexNet\n",
        "loss_fn = lpips.LPIPS(net='vgg')  # Using VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn3W7YxisDaK"
      },
      "outputs": [],
      "source": [
        "def load_predictions(predictions_file):\n",
        "    data = sio.loadmat(predictions_file)\n",
        "    # Assuming the data structure is known and 'predictions' is the key\n",
        "    predictions = {\n",
        "        'Baseline': data['predictions']['Baseline'][0, 0],\n",
        "        'Partial_Decoder': data['predictions']['Partial_Decoder'][0, 0],\n",
        "        'Full_Decoder': data['predictions']['Full_Decoder'][0, 0]\n",
        "    }\n",
        "    # Decode byte arrays if necessary\n",
        "    for key, value in predictions.items():\n",
        "        if isinstance(value, bytes):\n",
        "            # Example of decoding bytes to numpy array; adapt as needed\n",
        "            predictions[key] = np.frombuffer(value, dtype=np.float32).reshape((80, 192, 192, 3))\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHmtz_FNX_uB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "def prepare_image(image):\n",
        "    # Ensure the input image is a TensorFlow tensor with dtype float32\n",
        "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "\n",
        "    # Normalize the image tensor to [-1, 1]\n",
        "    image_min = tf.reduce_min(image)\n",
        "    image_max = tf.reduce_max(image)\n",
        "    image = 2 * (image - image_min) / (image_max - image_min) - 1\n",
        "\n",
        "    # Check and adapt the tensor dimensions\n",
        "    # Assumption: The last dimension is channels if it's exactly 3; otherwise, we assume 1 channel.\n",
        "    if image.shape[-1] != 3:\n",
        "        # If the image does not have three channels, we tile to create three channels\n",
        "        image = tf.tile(image, [1, 1, 3])  # This expects image to be at least 3D; reshape if not\n",
        "\n",
        "    # Ensure the image tensor is in the correct shape (channels, height, width)\n",
        "    image = tf.transpose(image, [2, 0, 1])\n",
        "\n",
        "    # Convert TensorFlow tensor to a PyTorch tensor\n",
        "    image = torch.from_numpy(image.numpy()).float()\n",
        "\n",
        "    # Ensure the image tensor has a batch dimension\n",
        "    if image.dim() == 3:\n",
        "        image = image.unsqueeze(0)\n",
        "\n",
        "    return image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3sD2tISYG12"
      },
      "outputs": [],
      "source": [
        "def compute_lpips(datadir, predictions_dir, cfg):\n",
        "    # loss_fn = lpips.LPIPS(net='alex')  # Initialize the LPIPS function\n",
        "    subject_scores = []\n",
        "    subjects = sorted([f for f in os.listdir(datadir) if f.startswith(\"BraTS2021_\")])\n",
        "\n",
        "    for subName in subjects:\n",
        "        print(f\"Processing {subName}...\")\n",
        "        img = load_subject(datadir, subName)\n",
        "        _, y_true = get_data(img, cfg.contrast_idx, cfg.target_contrast_idx)  # Ground truth images\n",
        "        y_true = y_true.numpy()\n",
        "\n",
        "        # Load predictions\n",
        "        predictions_file = f'{predictions_dir}/{subName}_predictions.mat'\n",
        "        predictions = load_predictions(predictions_file)\n",
        "\n",
        "        model_scores = {}\n",
        "        for model_name, y_pred in predictions.items():\n",
        "            scores = []\n",
        "            for i in range(y_true.shape[0]):  # Assuming y_true is numpy array\n",
        "                img0 = prepare_image(y_true[i])\n",
        "                # print(type(y_pred))\n",
        "                img1 = prepare_image(y_pred[i])\n",
        "                with torch.no_grad():\n",
        "                    score = loss_fn(img0, img1)\n",
        "                scores.append(score.item())\n",
        "            model_scores[model_name] = np.mean(scores)\n",
        "\n",
        "        subject_scores.append({\n",
        "            'Subject_ID': subName,\n",
        "            'Baseline_Avg_LPIPS': model_scores['Baseline'],\n",
        "            'Full_Decoder_Avg_LPIPS': model_scores['Full_Decoder'],\n",
        "            'Partial_Decoder_Avg_LPIPS': model_scores['Partial_Decoder']\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(subject_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyIjysLNZF32",
        "outputId": "b4ff54b3-ff0c-47a3-af82-6116cb7616a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing BraTS2021_00016...\n",
            "Processing BraTS2021_00488...\n",
            "Processing BraTS2021_00491...\n",
            "Processing BraTS2021_00494...\n",
            "Processing BraTS2021_00505...\n",
            "Processing BraTS2021_00510...\n",
            "Processing BraTS2021_00516...\n",
            "Processing BraTS2021_00533...\n",
            "Processing BraTS2021_00610...\n",
            "Processing BraTS2021_00618...\n",
            "Processing BraTS2021_00636...\n",
            "Processing BraTS2021_00674...\n",
            "Processing BraTS2021_00765...\n",
            "Processing BraTS2021_01100...\n",
            "Processing BraTS2021_01102...\n",
            "Processing BraTS2021_01105...\n",
            "Processing BraTS2021_01106...\n",
            "Processing BraTS2021_01112...\n",
            "Processing BraTS2021_01113...\n",
            "Processing BraTS2021_01114...\n",
            "Processing BraTS2021_01115...\n",
            "Processing BraTS2021_01117...\n",
            "Processing BraTS2021_01118...\n",
            "Processing BraTS2021_01120...\n",
            "Processing BraTS2021_01121...\n",
            "Processing BraTS2021_01124...\n",
            "Processing BraTS2021_01125...\n",
            "Processing BraTS2021_01128...\n",
            "Processing BraTS2021_01133...\n",
            "Processing BraTS2021_01137...\n",
            "Processing BraTS2021_01138...\n",
            "Processing BraTS2021_01150...\n",
            "Processing BraTS2021_01153...\n",
            "Processing BraTS2021_01154...\n",
            "Processing BraTS2021_01155...\n",
            "Processing BraTS2021_01156...\n",
            "Processing BraTS2021_01158...\n",
            "Processing BraTS2021_01159...\n",
            "Processing BraTS2021_01160...\n",
            "Processing BraTS2021_01162...\n",
            "Processing BraTS2021_01163...\n",
            "Processing BraTS2021_01164...\n",
            "Processing BraTS2021_01167...\n",
            "Processing BraTS2021_01170...\n",
            "Processing BraTS2021_01178...\n",
            "Processing BraTS2021_01179...\n",
            "Processing BraTS2021_01185...\n",
            "Processing BraTS2021_01193...\n",
            "Processing BraTS2021_01194...\n",
            "Processing BraTS2021_01195...\n",
            "Processing BraTS2021_01196...\n",
            "Processing BraTS2021_01198...\n",
            "Processing BraTS2021_01199...\n",
            "Processing BraTS2021_01200...\n",
            "Processing BraTS2021_01201...\n",
            "Processing BraTS2021_01203...\n",
            "Processing BraTS2021_01208...\n",
            "Processing BraTS2021_01210...\n",
            "Processing BraTS2021_01211...\n",
            "Processing BraTS2021_01213...\n",
            "Processing BraTS2021_01214...\n",
            "Processing BraTS2021_01215...\n",
            "Processing BraTS2021_01218...\n",
            "Processing BraTS2021_01301...\n",
            "Processing BraTS2021_01403...\n",
            "Processing BraTS2021_01500...\n",
            "Processing BraTS2021_01516...\n",
            "Processing BraTS2021_01583...\n",
            "Processing BraTS2021_01654...\n",
            "CSV file has been saved.\n"
          ]
        }
      ],
      "source": [
        "datadir = '/content/drive/Othercomputers/My Mac/Documents/GitHub/CCL-Synthetis/trained/BraTS2021_Test/'\n",
        "predictions_dir = '/content/drive/Othercomputers/My Mac/Documents/GitHub/CCL-Synthetis/trained/predictions/updated_loss5/'\n",
        "\n",
        "results_df = compute_lpips(datadir, predictions_dir, cfg)\n",
        "results_df.to_csv('/content/drive/Othercomputers/My Mac/Documents/Vgg_updated.csv', index=False)\n",
        "print('CSV file has been saved.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xK_ST9ztR5rk",
        "outputId": "baf4becb-812e-4adc-970e-c11e8345dcf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Subject_ID  Baseline_Avg_LPIPS  Full_Decoder_Avg_LPIPS  \\\n",
            "0   BraTS2021_00016            0.108612                0.092257   \n",
            "1   BraTS2021_00488            0.123527                0.100889   \n",
            "2   BraTS2021_00491            0.143819                0.133805   \n",
            "3   BraTS2021_00494            0.122170                0.099736   \n",
            "4   BraTS2021_00505            0.152652                0.142963   \n",
            "..              ...                 ...                     ...   \n",
            "64  BraTS2021_01403            0.163133                0.128086   \n",
            "65  BraTS2021_01500            0.149235                0.113174   \n",
            "66  BraTS2021_01516            0.165236                0.145060   \n",
            "67  BraTS2021_01583            0.130443                0.114228   \n",
            "68  BraTS2021_01654            0.165639                0.128517   \n",
            "\n",
            "    Partial_Decoder_Avg_LPIPS  \n",
            "0                    0.102396  \n",
            "1                    0.103158  \n",
            "2                    0.128996  \n",
            "3                    0.110969  \n",
            "4                    0.139636  \n",
            "..                        ...  \n",
            "64                   0.140191  \n",
            "65                   0.140198  \n",
            "66                   0.178543  \n",
            "67                   0.118500  \n",
            "68                   0.134473  \n",
            "\n",
            "[69 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}